{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import pandas as pd\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "from torch import optim\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  Load Model and Tokenize\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"ainize/bart-base-cnn\")\n",
    "model_bart = BartForConditionalGeneration.from_pretrained(\"ainize/bart-base-cnn\")\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"test_text.csv\")\n",
    "\n",
    "batch_size = 4  # choix de taille de batch appropri√©e\n",
    "num_batches = (len(test_data) + batch_size - 1) // batch_size\n",
    "\n",
    "generated_summaries = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_data = test_data.iloc[i * batch_size: (i + 1) * batch_size]\n",
    "    \n",
    "    test_encodings = tokenizer(batch_data[\"text\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bart.generate(input_ids=test_encodings[\"input_ids\"], max_length=50, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    decoded_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    generated_summaries.extend(decoded_summaries)\n",
    "\n",
    "submission_df = pd.DataFrame({\"ID\": test_data[\"ID\"], \"titles\": generated_summaries})\n",
    "\n",
    "submission_df.to_csv(\"bart_cnn_not_trained.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
