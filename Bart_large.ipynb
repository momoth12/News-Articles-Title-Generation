{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:26:24.960871Z","iopub.status.busy":"2024-03-25T14:26:24.960593Z","iopub.status.idle":"2024-03-25T14:27:01.904236Z","shell.execute_reply":"2024-03-25T14:27:01.903378Z","shell.execute_reply.started":"2024-03-25T14:26:24.960845Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["# Transformers\n","from transformers import BartTokenizer, BartForConditionalGeneration      # BERT Tokenizer and architecture\n","from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments         # These will help us to fine-tune our model\n","from transformers import pipeline                                         # Pipeline\n","from transformers import DataCollatorForSeq2Seq                           # DataCollator to batch the data \n","import torch                                                              # PyTorch\n","import pandas as pd\n","from datasets import load_metric, Dataset\n","\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-25T14:27:01.906594Z","iopub.status.busy":"2024-03-25T14:27:01.905979Z","iopub.status.idle":"2024-03-25T14:27:04.162688Z","shell.execute_reply":"2024-03-25T14:27:04.161768Z","shell.execute_reply.started":"2024-03-25T14:27:01.906563Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv('data/train.csv')\n","test_data = pd.read_csv('data/test_text.csv')\n","val_data = pd.read_csv('data/validation.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:04.164805Z","iopub.status.busy":"2024-03-25T14:27:04.164378Z","iopub.status.idle":"2024-03-25T14:27:04.171364Z","shell.execute_reply":"2024-03-25T14:27:04.170381Z","shell.execute_reply.started":"2024-03-25T14:27:04.164766Z"},"trusted":true},"outputs":[],"source":["def clean_tags(text):\n","    clean = re.compile('<.*?>') # Compiling tags\n","    clean = re.sub(clean, '', text) # Replacing tags text by an empty string\n","\n","    # Removing empty dialogues\n","    clean = '\\n'.join([line for line in clean.split('\\n') if not re.match('.*:\\s*$', line)])\n","\n","    return clean\n","\n","def clean_df(df, cols):\n","    for col in cols:\n","        df[col] = df[col].fillna('').apply(clean_tags)\n","    return df"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:04.174047Z","iopub.status.busy":"2024-03-25T14:27:04.173686Z","iopub.status.idle":"2024-03-25T14:27:04.642298Z","shell.execute_reply":"2024-03-25T14:27:04.641482Z","shell.execute_reply.started":"2024-03-25T14:27:04.174021Z"},"trusted":true},"outputs":[],"source":["train_data = clean_df(train_data,['text', 'titles'])\n","test_data = clean_df(test_data,['text'])\n","val_data = clean_df(val_data,['text', 'titles'])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:04.643684Z","iopub.status.busy":"2024-03-25T14:27:04.643373Z","iopub.status.idle":"2024-03-25T14:27:04.911983Z","shell.execute_reply":"2024-03-25T14:27:04.910974Z","shell.execute_reply.started":"2024-03-25T14:27:04.643657Z"},"trusted":true},"outputs":[],"source":["train_ds = Dataset.from_pandas(train_data)\n","test_ds = Dataset.from_pandas(test_data)\n","val_ds = Dataset.from_pandas(val_data)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:04.913486Z","iopub.status.busy":"2024-03-25T14:27:04.913215Z","iopub.status.idle":"2024-03-25T14:27:18.384144Z","shell.execute_reply":"2024-03-25T14:27:18.382971Z","shell.execute_reply.started":"2024-03-25T14:27:04.913462Z"},"trusted":true},"outputs":[],"source":["checkpoint = 'facebook/bart-large-xsum' # Model\n","tokenizer = BartTokenizer.from_pretrained(checkpoint) # Loading Tokenizer\n","model = BartForConditionalGeneration.from_pretrained(checkpoint).to('cuda')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:18.388200Z","iopub.status.busy":"2024-03-25T14:27:18.385442Z","iopub.status.idle":"2024-03-25T14:27:18.394430Z","shell.execute_reply":"2024-03-25T14:27:18.393502Z","shell.execute_reply.started":"2024-03-25T14:27:18.388172Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    inputs = [doc for doc in examples[\"text\"]]\n","    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"titles\"], max_length=128, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:27:18.395988Z","iopub.status.busy":"2024-03-25T14:27:18.395689Z","iopub.status.idle":"2024-03-25T14:29:33.484487Z","shell.execute_reply":"2024-03-25T14:29:33.483417Z","shell.execute_reply.started":"2024-03-25T14:27:18.395957Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21401/21401 [00:47<00:00, 447.29 examples/s]\n","Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:03<00:00, 454.55 examples/s]\n"]}],"source":["# Applying preprocess_function to the datasets\n","tokenized_train = train_ds.map(preprocess_function, batched=True,\n","                               remove_columns=['text', 'titles']) # Removing features\n","# Removing features\n","tokenized_val = val_ds.map(preprocess_function, batched=True,\n","                               remove_columns=['text', 'titles']) # Removing features"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:33.486402Z","iopub.status.busy":"2024-03-25T14:29:33.485949Z","iopub.status.idle":"2024-03-25T14:29:33.491198Z","shell.execute_reply":"2024-03-25T14:29:33.490313Z","shell.execute_reply.started":"2024-03-25T14:29:33.486353Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:33.494897Z","iopub.status.busy":"2024-03-25T14:29:33.494554Z","iopub.status.idle":"2024-03-25T14:29:51.043375Z","shell.execute_reply":"2024-03-25T14:29:51.042143Z","shell.execute_reply.started":"2024-03-25T14:29:33.494874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge_score in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n","Requirement already satisfied: absl-py in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (2.0.0)\n","Requirement already satisfied: nltk in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in c:\\users\\mouha\\appdata\\roaming\\python\\python310\\site-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (2023.10.3)\n","Requirement already satisfied: tqdm in c:\\users\\mouha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\mouha\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"]},{"name":"stderr","output_type":"stream","text":["DEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n","\n","[notice] A new release of pip is available: 23.3.2 -> 24.0\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:51.045344Z","iopub.status.busy":"2024-03-25T14:29:51.045020Z","iopub.status.idle":"2024-03-25T14:29:52.411952Z","shell.execute_reply":"2024-03-25T14:29:52.410916Z","shell.execute_reply.started":"2024-03-25T14:29:51.045313Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\mouha\\AppData\\Local\\Temp\\ipykernel_31148\\1264828061.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric('rouge')\n","c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:753: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]}],"source":["metric = load_metric('rouge')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:52.413619Z","iopub.status.busy":"2024-03-25T14:29:52.413299Z","iopub.status.idle":"2024-03-25T14:29:52.424139Z","shell.execute_reply":"2024-03-25T14:29:52.423116Z","shell.execute_reply.started":"2024-03-25T14:29:52.413592Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred# Obtaining predictions and true labels\n","    \n","    # Decoding predictions\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    \n","    # Obtaining the true labels tokens, while eliminating any possible masked token (i.e., label = -100)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    \n","    # Computing rouge score\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()} # Extracting some results\n","\n","    # Add mean-generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:52.425836Z","iopub.status.busy":"2024-03-25T14:29:52.425512Z","iopub.status.idle":"2024-03-25T14:29:52.487333Z","shell.execute_reply":"2024-03-25T14:29:52.486404Z","shell.execute_reply.started":"2024-03-25T14:29:52.425809Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using amp half precision backend\n"]}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir = 'bart_samsum',\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = 'epoch',\n","    load_best_model_at_end = True,\n","    metric_for_best_model = 'eval_loss',\n","    seed = 8,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=2,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    fp16=True,\n","    report_to=\"none\"\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_val,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T14:29:52.488732Z","iopub.status.busy":"2024-03-25T14:29:52.488423Z","iopub.status.idle":"2024-03-25T14:36:52.736605Z","shell.execute_reply":"2024-03-25T14:36:52.735236Z","shell.execute_reply.started":"2024-03-25T14:29:52.488706Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 21401\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 8025\n","  0%|          | 3/8025 [00:45<35:46:01, 16.05s/it]"]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:36:52.737627Z","iopub.status.idle":"2024-03-25T14:36:52.738018Z","shell.execute_reply":"2024-03-25T14:36:52.737843Z","shell.execute_reply.started":"2024-03-25T14:36:52.737827Z"},"trusted":true},"outputs":[],"source":["# Saving model to a custom directory\n","directory = \"bart_finetuned\"\n","trainer.save_model(directory)\n","\n","# Saving model tokenizer\n","tokenizer.save_pretrained(directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:36:52.739717Z","iopub.status.idle":"2024-03-25T14:36:52.740129Z","shell.execute_reply":"2024-03-25T14:36:52.739944Z","shell.execute_reply.started":"2024-03-25T14:36:52.739912Z"},"trusted":true},"outputs":[],"source":["shutil.make_archive('bart_finetuned', 'zip', '/kaggle/working/bart_finetuned')\n","shutil.move('bart_finetuned.zip', '/kaggle/working/bart_finetuned.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4616152,"sourceId":7867765,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
